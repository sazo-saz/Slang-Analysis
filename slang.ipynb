{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install transformers nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nrzpn3fMwwKP","executionInfo":{"status":"ok","timestamp":1731342758514,"user_tz":-330,"elapsed":4635,"user":{"displayName":"Advait Iyer","userId":"11764060739685904455"}},"outputId":"de9beb73-f78b-404d-ffe2-733b80e2fa97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"]}]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"nF5I3E62MiOX"}},{"cell_type":"code","source":["import gzip\n","import pandas as pd\n","import re\n","from nltk.corpus import wordnet, sentiwordnet as swn\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","import nltk\n","from nltk.corpus import wordnet\n","import json\n","import os"],"metadata":{"id":"7ZQahi90wyXh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.corpus import wordnet# Uncomment the below line if you haven't downloaded these NLTK resources\n","nltk.download('vader_lexicon')\n","nltk.download('wordnet')\n","nltk.download('sentiwordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zj5tgCabw0L2","executionInfo":{"status":"ok","timestamp":1731318313650,"user_tz":-330,"elapsed":1774,"user":{"displayName":"SOPHIA AGNES J","userId":"17435315099430529031"}},"outputId":"a1088f6d-8c4a-4027-da68-18ffb018da9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XgtGievNPocz","colab":{"base_uri":"https://localhost:8080/","height":347},"outputId":"47cad58a-c65b-485d-86c4-34deb337ca7f","executionInfo":{"status":"error","timestamp":1731318782719,"user_tz":-330,"elapsed":895,"user":{"displayName":"SOPHIA AGNES J","userId":"17435315099430529031"}}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'process_review' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-b49dbd3fd239>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Run the processing function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mreview_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_reviews_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-b49dbd3fd239>\u001b[0m in \u001b[0;36mprocess_reviews_from_json\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;31m# Process the review and get the sentiment score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mslang_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_slang_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_review\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# Append the results to a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'process_review' is not defined"]}],"source":["def load_slang_dict():\n","  current_directory = os.getcwd()\n","  slang_file_path = os.path.join(current_directory, \"slang words.xlsx\")\n","\n","  if os.path.exists(slang_file_path):\n","      try:\n","          slang_df = pd.read_excel(slang_file_path)\n","          slang_dict = dict(zip(slang_df['Slang Word'], slang_df['Meaning']))\n","          return slang_dict\n","      except Exception as e:\n","          print(f\"Error loading slang dictionary: {e}\")\n","          return {}  # Return an empty dictionary in case of error\n","  else:\n","      print(f\"Error: Slang dictionary file not found at {slang_file_path}\")\n","      return {}  # Return an empty dictionary in case of error\n","slang_dict = load_slang_dict()\n","slang_df = pd.read_excel(\"/content/slang words.xlsx\")  # Adjust path if necessary\n","slang_dict = dict(zip(slang_df['Slang Word'], slang_df['Meaning']))\n","\n","english_words = set(wordnet.words())\n","\n","\n","sentiment_analyzer = SentimentIntensityAnalyzer()\n","\n","english_words = set(wordnet.words())\n","\n","\n","def process_reviews_from_json(file_path):\n","    results = []\n","    # Open the GZIP file\n","    with gzip.open(\"/content/All_Beauty.jsonl (1) (1).gz\", 'rt', encoding='utf-8') as f:\n","        for line in f:\n","            try:\n","                review_data = json.loads(line)  # Load each review as a JSON object\n","                title = review_data.get('title', '')\n","                text = review_data.get('text', '')\n","                review_text = title + \" \" + text   # Extract the review text\n","\n","                # Process the review and get the sentiment score\n","                slang_scores, final_slang_score = process_review(review_text)\n","\n","                # Append the results to a list\n","                results.append({\n","                    'reviewText': review_text,\n","                    'slangScores': slang_scores,\n","                    'finalSlangScore': final_slang_score\n","                })\n","\n","            except json.JSONDecodeError as e:\n","                print(f\"Error decoding JSON: {e}\")\n","\n","    return results\n","\n","current_directory = os.getcwd()\n","json_file_path = os.path.join(current_directory, \"All_Beauty.jsonl (1).gz\")\n","\n","# Run the processing function\n","review_results = process_reviews_from_json(json_file_path)\n","\n","def preprocess_text(text):\n","    # Remove non-alphabetic characters and filter out non-English words\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","    words = text.split()\n","    processed_words = [word for word in words if word in english_words or word in slang_dict]\n","    return processed_words\n","\n","def identify_slang(words):\n","    # Identify slang words in the text\n","    slang_words = [word for word in words if word in slang_dict]\n","    return slang_words\n","\n","\n","# Sentiment scoring function using SentiWordNet\n","def sentiment_score_sentiwordnet(word):\n","    # Attempt to retrieve SentiWordNet sentiment scores\n","    synsets = list(swn.senti_synsets(word))\n","    if synsets:\n","        # Calculate average sentiment scores\n","        pos_score = sum(syn.pos_score() for syn in synsets) / len(synsets)\n","        neg_score = sum(syn.neg_score() for syn in synsets) / len(synsets)\n","        # Assign categories based on scores (0=Negative, 1=Neutral, 2=Positive)\n","        if pos_score > neg_score:\n","            return 2  # Positive\n","        elif neg_score > pos_score:\n","            return 0  # Negative\n","        else:\n","            return 1  # Neutral\n","    else:\n","        # Default to neutral if no SentiWordNet score is found\n","        return 1\n","\n","def sentiment_score(slang_words, slang_dictionary):\n","    # Get sentiment score for each slang term\n","    scores = {}\n","    for slang in slang_words:\n","        if slang in english_words:\n","            scores[slang] = sentiment_score_sentiwordnet(slang)\n","        else:\n","            # Fallback to VADER if not found in SentiWordNet\n","            expanded_text = slang_dictionary.get(slang, slang)  # Use passed dictionary\n","            score = sentiment_analyzer.polarity_scores(expanded_text)[\"compound\"]\n","            if score >= 0.05:\n","                scores[slang] = 2  # Positive\n","            elif score <= -0.05:\n","                scores[slang] = 0  # Negative\n","            else:\n","                scores[slang] = 1  # Neutral\n","    return scores\n","\n","def enhance_words(slang_scores):\n","    # Optional: Enhance slang words based on additional web resources (pseudo-code)\n","    enhanced_scores = {}\n","    for slang, score in slang_scores.items():\n","        # Example of modifying score (here we keep it simple)\n","        enhanced_scores[slang] = score * 1.1  # Hypothetical enhancement\n","    return enhanced_scores\n","\n","# Get sentiment score for slang words using SentiWordNet or VADER\n","def sentiment_score(slang_words, slang_dictionary):  # Pass slang_dict as argument\n","    scores = {}\n","    for slang in slang_words:\n","        # Use SentiWordNet if available, fallback to VADER\n","        if slang in english_words:\n","            scores[slang] = sentiment_score_sentiwordnet(slang)\n","        else:\n","            # Fallback to VADER if not found in SentiWordNet\n","            expanded_text = slang_dictionary.get(slang, slang)  # Use passed dictionary\n","            score = sentiment_analyzer.polarity_scores(expanded_text)[\"compound\"]\n","            if score >= 0.05:\n","                scores[slang] = 2  # Positive\n","            elif score <= -0.05:\n","                scores[slang] = 0  # Negative\n","            else:\n","                scores[slang] = 1  # Neutral\n","    return scores\n","\n","\n","\n","def get_final_slang_score(slang_scores):\n","    # Calculate final slang score by averaging\n","    if slang_scores:\n","        final_score = round(sum(slang_scores.values()) / len(slang_scores))\n","    else:\n","        final_score = 1\n","    return final_score\n","\n","# Main function to process reviews\n","def process_review(review):\n","    # Step 1: Preprocess the text\n","    processed_words = preprocess_text(review)\n","\n","    # Step 2: Filter for slang words\n","    slang_words = identify_slang(processed_words)\n","\n","    if not slang_words:\n","        return \"No slang detected\", 1  # No slang found\n","\n","    # Step 3: Sentiment scoring\n","    slang_scores = sentiment_score(slang_words, slang_dict)\n","\n","    # Step 4: Enhance words (optional)\n","    enhanced_scores = enhance_words(slang_scores)\n","\n","    # Step 5: Final slang score\n","    final_score = get_final_slang_score(enhanced_scores)\n","\n","    return slang_scores, final_score\n","\n","def process_reviews_from_json(file_path):\n","    results = []\n","    try:\n","        # Open the GZIP file in read binary mode ('rb')\n","        with gzip.open(file_path, 'rb') as f:  # Changed to 'rb'\n","            # Decode data while reading to handle potential encoding issues\n","            for line in f:\n","                try:\n","                    review_data = json.loads(line.decode('utf-8'))\n","                    # ... (rest of your review processing logic) ...\n","                except json.JSONDecodeError as e:\n","                    print(f\"Error decoding JSON: {e}\")\n","    except EOFError as e:\n","        print(f\"EOFError encountered: {e}. The file may be corrupted or incomplete.\")\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","    return results\n","\n","current_directory = os.getcwd()\n","\n","json_file_path = os.path.join(current_directory, \"/content/All_Beauty.jsonl (1).gz\")\n","\n","review_results = process_reviews_from_json(\"/content/All_Beauty.jsonl (1).gz\")\n","# Example usage\n","for result in review_results:\n","    print(\"Review Text:\", result['reviewText'])\n","    print(\"Slang Scores:\", result['slangScores'])\n","    print(\"Final Slang Score:\", result['finalSlangScore'])\n","    print(\"---\")\n"]}]}